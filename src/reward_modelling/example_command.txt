deepspeed src/reward_modelling/reward_model.py \
--model_name_or_path="facebook/xglm-7.5B" \
--output_dir="/nlp/scr/fongsu/reward_model_HH/test/" \
--logging_steps=10 \
--per_device_train_batch_size=4 \
--num_train_epochs=1 \
--do_eval=False \
--save_strategy="no" \
--learning_rate=1e-5 \
--weight_decay=0.001 \
--report_to="wandb" \
--gradient_checkpointing=True \
--ddp_find_unused_parameters=False \
--deepspeed src/reward_modelling/ds_configs/stage_3_config.json

deepspeed src/reward_modelling/reward_model.py \
--model_name_or_path="EleutherAI/gpt-neo-1.3B" \
--output_dir="/nlp/src/fongsu/reward_model_HH/train_first_half/" \
--logging_steps=10 \
--per_device_train_batch_size=16 \
--per_device_eval_batch_size=16 \
--num_train_epochs=1 \
--do_eval=True \
--evaluation_strategy="steps" \
--eval_steps=1000 \
--save_total_limit=5 \
--save_strategy="steps" \
--save_steps=1000 \
--learning_rate=1e-5 \
--weight_decay=0.001 \
--report_to="wandb" \
--gradient_checkpointing=True \
--ddp_find_unused_parameters=False \
--push_to_hub=True \
--hub_model_id='gptneo-1.3B-rm-combined-train-first-half' \
--deepspeed src/reward_modelling/ds_configs/stage_3_config.json
