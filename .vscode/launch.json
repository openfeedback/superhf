{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "SHF Iter (Mock)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/superhf/shf_iterative_v1/run_shf_iterative.py",
            "console": "integratedTerminal",
            "args": [
                "--config",
                "${workspaceFolder}/experiments/superhf/shf_iterative_v1/configs/mock.yaml",
            ],
            "justMyCode": false
        },
        {
            "name": "SHF Iter (Neo-125M)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/superhf/shf_iterative_v1/run_shf_iterative.py",
            "console": "integratedTerminal",
            "args": [
                "--config",
                "${workspaceFolder}/experiments/superhf/shf_iterative_v1/configs/gpt-neo-125M.yaml",
            ],
            "justMyCode": false
        },
        {
            "name": "SHF Iter (Default)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/superhf/shf_iterative_v1/run_shf_iterative.py",
            "console": "integratedTerminal",
            "args": [
                "--config",
                "${workspaceFolder}/experiments/superhf/shf_iterative_v1/configs/default.yaml",
            ],
            "justMyCode": false
        },
        {
            "name": "SHF Iter (Debug)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/superhf/shf_iterative_v1/run_shf_iterative.py",
            "console": "integratedTerminal",
            "args": [
                "--config",
                "${workspaceFolder}/experiments/superhf/shf_iterative_v1/configs/debug.yaml",
            ],
            "justMyCode": false
        },
        {
            "name": "SHF Iter (Pythia 3B Debug Offload)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/superhf/shf_iterative_v1/run_shf_iterative.py",
            "console": "integratedTerminal",
            "args": [
                "--config",
                "${workspaceFolder}/experiments/superhf/shf_iterative_v1/configs/debug.yaml",
                "language_model_name=theblackcat102/pythia-3b-deduped-sft-r1",
                "cpu_offload=True",
            ],
            "justMyCode": false
        },
        {
            "name": "SHF Iter (Sweep)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/superhf/shf_iterative_v1/run_shf_iterative.py",
            "console": "integratedTerminal",
            "args": [
                "--sweep",
                "${workspaceFolder}/experiments/superhf/shf_iterative_v1/sweeps/params.yaml",
            ],
            "justMyCode": false
        },
        {
            "name": "GPT Generation Script",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/openai_generations/generate_anwers.py",
            "console": "integratedTerminal",
            "args": [
                "--key",
                "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",
                "--engine",
                "gpt-3.5-turbo",
                "--debug"
            ],
            "justMyCode": false
        },
        {
            "name": "RLHF (Mock)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/rlhf/rlhf_v1/run_rlhf.py",
            "console": "integratedTerminal",
            "args": [
                "--config",
                "${workspaceFolder}/experiments//rlhf/rlhf_v1/configs/mock.yaml",
            ],
            "justMyCode": false
        },
        {
            "name": "SHF Debug (Sweep)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/superhf/shf_iterative_v1/run_shf_iterative.py",
            "console": "integratedTerminal",
            "args": [
                "--config",
                "${workspaceFolder}/experiments/superhf/shf_iterative_v1/configs/debug.yaml",
                "--sweep",
                "${workspaceFolder}/experiments/superhf/shf_iterative_v1/sweeps/params.yaml",
            ],
            "justMyCode": false
        },
        {
            "name": "Test set evalulation",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/evaluations/score_completions.py",
            "console": "integratedTerminal",
            "args": [
                "--config",
                "${workspaceFolder}/experiments/evaluations/configs/debug.yaml",
            ],
            "justMyCode": true
        },
        {
            "name": "Test set evalulation (real lm)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/evaluations/score_completions.py",
            "console": "integratedTerminal",
            "args": [
                "--config",
                "${workspaceFolder}/experiments/evaluations/configs/generate_completions_jag_pythia_eleuther_0_6.yaml",
            ],
            "justMyCode": true
        },
        {
            "name": "LM Evals Debug",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/evaluations/run_lm_evals.py",
            "console": "integratedTerminal",
            "args": [
                "--models",
                // "EleutherAI/pythia-70m-deduped",
                "gmukobi/model-test-pythia-70m-A@step-0001",
                "gmukobi/model-test-pythia-70m-A",
                // "gmukobi/model-test-pythia-70m-B",
                "facebook/opt-125m",
                // "gmukobi/model-test-opt-125m-C",
                "--tasks",
                // "math_precalc",
                "hendrycksTest-global_facts",
                "cb",
                "--output_folder",
                "debug",
                "--batch_size",
                "16",
            ],
            "justMyCode": false
        },
        {
            "name": "FTP Debug",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/sft/sft_ftp_and_instruct.py",
            "console": "integratedTerminal",
            "args": [
                "--model_name",
                "EleutherAI/pythia-70m-deduped",
                "--num_examples",
                "500",
                "--data_type",
                "ftp",
                "--batch_size",
                "8",
                "--scheduler_warmup_steps",
                "1",
                "--mixed_precision",
                "none",
                "--lora_target_modules",
                "query_key_value",
                "--push_interval",
                "256",
            ],
            "justMyCode": false,
        },
        {
            "name": "SFT Debug",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/sft/sft_ftp_and_instruct.py",
            "console": "integratedTerminal",
            "args": [
                "--model_name",
                "EleutherAI/pythia-70m-deduped",
                "--num_examples",
                "500",
                "--data_type",
                "instruct",
                "--batch_size",
                "8",
                "--scheduler_warmup_steps",
                "1",
                "--mixed_precision",
                "none",
                "--lora_target_modules",
                "query_key_value",
                "--push_interval",
                "256",
            ],
            "justMyCode": false,
        },
        {
            "name": "Advanced AI Risk Evals Debug",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/experiments/evaluations/run_advanced_ai_risk_evals.py",
            "console": "integratedTerminal",
            "args": [
                "--models",
                "EleutherAI/pythia-70m-deduped",
                "facebook/opt-125m",
                "gpt2",
                "EleutherAI/pythia-1b-deduped",
                // "gmukobi/model-test-pythia-70m-A@step-0001",
                // "gmukobi/model-test-pythia-70m-A",
                // "gmukobi/model-test-pythia-70m-B",
                "--batch_size",
                "4",
            ],
            "justMyCode": false
        },
    ]
}
