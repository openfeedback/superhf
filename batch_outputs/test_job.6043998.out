SLURM_JOBID=6043998
SLURM_JOB_NODELIST=jagupard12
SLURM_NNODES=1
SLURMTMPDIR=
working directory = /sailhome/fongsu/superhf
[2023-04-25 18:26:35,974] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3: setting --include=localhost:0,1,2,3
[2023-04-25 18:26:36,005] [INFO] [runner.py:540:main] cmd = /sailhome/fongsu/rm/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None src/reward_modelling/reward_model.py --model_name_or_path=distilbert-base-uncased --output_dir=/nlp/scr/fongsu/rm_combined/new_distilbert_train_second_half/ --logging_steps=100 --per_device_train_batch_size=8 --per_device_eval_batch_size=8 --gradient_accumulation_steps=4 --num_train_epochs=1 --do_eval=True --evaluation_strategy=steps --eval_steps=100 --save_total_limit=5 --save_strategy=steps --save_steps=500 --learning_rate=1e-5 --weight_decay=0.001 --fp16=True --report_to=wandb --gradient_checkpointing=True --ddp_find_unused_parameters=False --deepspeed src/reward_modelling/ds_configs/base_configs.json
[2023-04-25 18:26:44,686] [INFO] [launch.py:222:main] 0 NCCL_P2P_DISABLE=1
[2023-04-25 18:26:44,686] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2023-04-25 18:26:44,686] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=4, node_rank=0
[2023-04-25 18:26:44,686] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2023-04-25 18:26:44,686] [INFO] [launch.py:247:main] dist_world_size=4
[2023-04-25 18:26:44,686] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2023-04-25 18:26:52,398] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
04/25/2023 18:26:58 - WARNING - datasets.builder - Found cached dataset webgpt_comparisons (/nlp/scr/fongsu/.cache/openai___webgpt_comparisons/default/0.0.0/8b5d5879cdc98c4c0099af6053dffe8d504588d43d3b11f1b1ec223ab1e8db0a)
04/25/2023 18:26:58 - WARNING - datasets.builder - Found cached dataset webgpt_comparisons (/nlp/scr/fongsu/.cache/openai___webgpt_comparisons/default/0.0.0/8b5d5879cdc98c4c0099af6053dffe8d504588d43d3b11f1b1ec223ab1e8db0a)
04/25/2023 18:26:58 - WARNING - datasets.builder - Found cached dataset webgpt_comparisons (/nlp/scr/fongsu/.cache/openai___webgpt_comparisons/default/0.0.0/8b5d5879cdc98c4c0099af6053dffe8d504588d43d3b11f1b1ec223ab1e8db0a)
04/25/2023 18:26:58 - WARNING - datasets.builder - Found cached dataset webgpt_comparisons (/nlp/scr/fongsu/.cache/openai___webgpt_comparisons/default/0.0.0/8b5d5879cdc98c4c0099af6053dffe8d504588d43d3b11f1b1ec223ab1e8db0a)
04/25/2023 18:27:13 - WARNING - datasets.builder - Using custom data configuration Anthropic--hh-rlhf-c8cd8dc58ab67414
04/25/2023 18:27:13 - WARNING - datasets.builder - Found cached dataset json (/nlp/scr/fongsu/.cache/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
04/25/2023 18:27:13 - WARNING - datasets.builder - Using custom data configuration Anthropic--hh-rlhf-c8cd8dc58ab67414
04/25/2023 18:27:13 - WARNING - datasets.builder - Found cached dataset json (/nlp/scr/fongsu/.cache/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
04/25/2023 18:27:14 - WARNING - datasets.builder - Using custom data configuration Anthropic--hh-rlhf-c8cd8dc58ab67414
04/25/2023 18:27:14 - WARNING - datasets.builder - Found cached dataset json (/nlp/scr/fongsu/.cache/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
04/25/2023 18:27:14 - WARNING - datasets.builder - Using custom data configuration Anthropic--hh-rlhf-c8cd8dc58ab67414
04/25/2023 18:27:14 - WARNING - datasets.builder - Found cached dataset json (/nlp/scr/fongsu/.cache/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
04/25/2023 18:27:17 - WARNING - datasets.builder - Found cached dataset summarize_from_feedback (/nlp/scr/fongsu/.cache/openai___summarize_from_feedback/comparisons/0.0.0/483f970ceb55b926b0a087ef4f678ab1b089bc8174a107a452c6152e88af7ff0)
04/25/2023 18:27:18 - WARNING - datasets.builder - Found cached dataset summarize_from_feedback (/nlp/scr/fongsu/.cache/openai___summarize_from_feedback/comparisons/0.0.0/483f970ceb55b926b0a087ef4f678ab1b089bc8174a107a452c6152e88af7ff0)
04/25/2023 18:27:18 - WARNING - datasets.builder - Found cached dataset summarize_from_feedback (/nlp/scr/fongsu/.cache/openai___summarize_from_feedback/comparisons/0.0.0/483f970ceb55b926b0a087ef4f678ab1b089bc8174a107a452c6152e88af7ff0)
04/25/2023 18:27:18 - WARNING - datasets.builder - Found cached dataset summarize_from_feedback (/nlp/scr/fongsu/.cache/openai___summarize_from_feedback/comparisons/0.0.0/483f970ceb55b926b0a087ef4f678ab1b089bc8174a107a452c6152e88af7ff0)
04/25/2023 18:27:28 - WARNING - datasets.builder - Using custom data configuration Dahoas--synthetic-instruct-gptj-pairwise-0b2fd7bd9ea121cb
04/25/2023 18:27:28 - WARNING - datasets.builder - Found cached dataset parquet (/nlp/scr/fongsu/.cache/Dahoas___parquet/Dahoas--synthetic-instruct-gptj-pairwise-0b2fd7bd9ea121cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)
04/25/2023 18:27:28 - WARNING - datasets.builder - Using custom data configuration Dahoas--synthetic-instruct-gptj-pairwise-0b2fd7bd9ea121cb
04/25/2023 18:27:28 - WARNING - datasets.builder - Found cached dataset parquet (/nlp/scr/fongsu/.cache/Dahoas___parquet/Dahoas--synthetic-instruct-gptj-pairwise-0b2fd7bd9ea121cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)
04/25/2023 18:27:29 - WARNING - datasets.builder - Using custom data configuration Dahoas--synthetic-instruct-gptj-pairwise-0b2fd7bd9ea121cb
04/25/2023 18:27:29 - WARNING - datasets.builder - Found cached dataset parquet (/nlp/scr/fongsu/.cache/Dahoas___parquet/Dahoas--synthetic-instruct-gptj-pairwise-0b2fd7bd9ea121cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)
[2023-04-25 18:27:29,983] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.0, git-hash=unknown, git-branch=unknown
[2023-04-25 18:27:29,984] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2023-04-25 18:27:30,088] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
04/25/2023 18:27:30 - WARNING - datasets.builder - Using custom data configuration Dahoas--synthetic-instruct-gptj-pairwise-0b2fd7bd9ea121cb
04/25/2023 18:27:30 - WARNING - datasets.builder - Found cached dataset parquet (/nlp/scr/fongsu/.cache/Dahoas___parquet/Dahoas--synthetic-instruct-gptj-pairwise-0b2fd7bd9ea121cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)
[2023-04-25 18:27:30,668] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2023-04-25 18:27:32,010] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead
[2023-04-25 18:27:36,313] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Time to load cpu_adam op: 5.599530220031738 seconds
Time to load cpu_adam op: 5.715771198272705 seconds
Time to load cpu_adam op: 5.712736368179321 seconds
Time to load cpu_adam op: 5.711641550064087 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000010, betas=(0.900000, 0.999000), weight_decay=0.001000, adam_w=1
[2023-04-25 18:27:46,684] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2023-04-25 18:27:46,688] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2023-04-25 18:27:46,688] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2023-04-25 18:27:46,688] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[2023-04-25 18:27:46,688] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 200000000
[2023-04-25 18:27:46,688] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 200000000
[2023-04-25 18:27:46,688] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True
[2023-04-25 18:27:46,688] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
ninja: no work to do.
Time to load utils op: 0.7153258323669434 seconds
Time to load utils op: 0.7085971832275391 seconds
Time to load utils op: 0.7051239013671875 seconds
Time to load utils op: 0.7059361934661865 seconds
Rank: 3 partition count [4] and sizes[(16590912, False)] 
Rank: 0 partition count [4] and sizes[(16590912, False)] 
Rank: 1 partition count [4] and sizes[(16590912, False)] 
Rank: 2 partition count [4] and sizes[(16590912, False)] 
[2023-04-25 18:27:48,694] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-04-25 18:27:48,695] [INFO] [utils.py:786:see_memory_usage] MA 0.17 GB         Max_MA 0.17 GB         CA 0.17 GB         Max_CA 0 GB 
[2023-04-25 18:27:48,695] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 9.89 GB, percent = 7.9%
[2023-04-25 18:27:48,799] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 3886913
[2023-04-25 18:27:49,431] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 3886914
[2023-04-25 18:27:49,447] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 3886915
[2023-04-25 18:27:49,456] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 3886916
[2023-04-25 18:27:49,456] [ERROR] [launch.py:434:sigkill_handler] ['/sailhome/fongsu/rm/bin/python', '-u', 'src/reward_modelling/reward_model.py', '--local_rank=3', '--model_name_or_path=distilbert-base-uncased', '--output_dir=/nlp/scr/fongsu/rm_combined/new_distilbert_train_second_half/', '--logging_steps=100', '--per_device_train_batch_size=8', '--per_device_eval_batch_size=8', '--gradient_accumulation_steps=4', '--num_train_epochs=1', '--do_eval=True', '--evaluation_strategy=steps', '--eval_steps=100', '--save_total_limit=5', '--save_strategy=steps', '--save_steps=500', '--learning_rate=1e-5', '--weight_decay=0.001', '--fp16=True', '--report_to=wandb', '--gradient_checkpointing=True', '--ddp_find_unused_parameters=False', '--deepspeed', 'src/reward_modelling/ds_configs/base_configs.json'] exits with return code = -4
