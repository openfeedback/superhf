python ./experiments/evaluations/run_lm_evals.py \
 --models \
 /juice5/scr5/nlp/llama_model/llama_hf_latest/llama-7b \
 /juice5/scr5/nlp/llama_model/alpaca_7b \
 gmukobi/shf-7b-kl-0.25 \
 gmukobi/shf-7b-accum-1 \
 gmukobi/shf-7b-gold-v1 \
 --tasks
 BoolQ \
 PIQA \
 SIQA \
 HellaSwag \
 WinoGrande \
 ARC-e \
 ARC-c \
 OBQA \
 TriviaQA \
 --output_folder \
 common_sense
